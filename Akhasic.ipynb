{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Akhasic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gungni/Ramon/blob/master/Akhasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyl5Zvs6Ru8a"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTS1bc_LR30V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719abac7-c326-4ef9-9b20-beec295e4cff"
      },
      "source": [
        "# https://drive.google.com/file/d/1Tm9v6es-0lH8u_w4Sb_ni4g7VgF61ekP/view?usp=sharing\n",
        "!gdown --id 1Tm9v6es-0lH8u_w4Sb_ni4g7VgF61ekP -O corpus.zip\n",
        "!unzip corpus.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Tm9v6es-0lH8u_w4Sb_ni4g7VgF61ekP\n",
            "To: /content/corpus.zip\n",
            "\r  0% 0.00/914k [00:00<?, ?B/s]\r100% 914k/914k [00:00<00:00, 60.7MB/s]\n",
            "Archive:  corpus.zip\n",
            "  inflating: corpus.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls9SwIgTSAC6"
      },
      "source": [
        "df = pd.read_csv('corpus.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naOEjYs-ZtDx"
      },
      "source": [
        "df['Rotulo'] = df['Rotulo'].apply(lambda x: str(x).replace(\"1.0\",\"1\"))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdpdv9p4Zs7W"
      },
      "source": [
        "df['Rotulo'] = df['Rotulo'].apply(lambda x: str(x).replace(\"0.0\",\"0\")) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5gsysmxZsuq"
      },
      "source": [
        "df['Rotulo'] = df['Rotulo'].apply(lambda x: str(x).replace(\"2.0\",\"2\")) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTNFie346ewi"
      },
      "source": [
        "filtrado = df.loc[df['Rotulo']!='0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e0qjiQy6emw"
      },
      "source": [
        "filtrado = filtrado.loc[df['Conteudo']!='1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBPunZsZ23nm",
        "outputId": "84475996-eacf-43ad-d293-20edbb4c246d"
      },
      "source": [
        "import nltk\n",
        "# nltk.download(\"stopwords\")  # stopwords\n",
        "nltk.download(\"punkt\")  # tokenizador\n",
        "# nltk.download('rslp')\n",
        "# nltk.download('wordnet')\n",
        "from nltk import word_tokenize "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sshIDA56VtF5",
        "outputId": "d910aafb-2cfd-4ce9-ee1e-c1248bf13c28"
      },
      "source": [
        "print(len(filtrado))\n",
        "print(filtrado.groupby('Rotulo').count())\n",
        "\n",
        "desinformacao = filtrado.loc[filtrado['Rotulo'] == '2']\n",
        "tokens = 0\n",
        "for i in desinformacao['Conteudo']:\n",
        "  tokens += len(word_tokenize(i, language='portuguese'))\n",
        "\n",
        "print(f'Total de tokens: {tokens}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12027\n",
            "        Conteudo\n",
            "Rotulo          \n",
            "1          11484\n",
            "2            543\n",
            "Total de tokens: 16264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBvd5sGBXkCT",
        "outputId": "764969bc-66b8-4d46-d05a-088a4b650b0f"
      },
      "source": [
        "data = filtrado\n",
        "\n",
        "corpus = data['Conteudo']  # Tweets\n",
        "y = data['Rotulo']  # Rótulos (manual)\n",
        "\n",
        "bow = CountVectorizer()\n",
        "X = bow.fit_transform(corpus)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% Treino -> 20% Teste\n",
        "\n",
        "#print(X_train)\n",
        "#exit()\n",
        "\n",
        "# print(X_train[:10])\n",
        "# print(y_train[:10])\n",
        "\n",
        "\n",
        "# train = pd.read_csv(\"corpus.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# X_train = bow.transform(train[\"Conteudo\"])\n",
        "# y_train = list(train[\"Rotulo\"])\n",
        "\n",
        "classifier = MLPClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0DmVpDQYqmg"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHWG-nSPYuVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9841f056-9739-4adb-a45a-132f19845ec1"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqoI-ShIY3ip",
        "outputId": "d4c2673e-2f6c-4b71-ca39-670dfc76cd10"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11424    1\n",
            "8041     1\n",
            "12501    1\n",
            "5663     1\n",
            "6699     1\n",
            "        ..\n",
            "12087    1\n",
            "4078     1\n",
            "5127     1\n",
            "11072    1\n",
            "3793     1\n",
            "Name: Rotulo, Length: 2406, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb7Pte8wY8kh",
        "outputId": "4d4a42ba-6158-4d8e-84b9-8ad3ff1e4cf8"
      },
      "source": [
        "#@title Texto de título predefinido\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.99      0.98      2303\n",
            "           2       0.48      0.28      0.35       103\n",
            "\n",
            "    accuracy                           0.96      2406\n",
            "   macro avg       0.72      0.63      0.67      2406\n",
            "weighted avg       0.95      0.96      0.95      2406\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQn7yJDcZG9Z"
      },
      "source": [
        "INICIO DA UTILIZAÇAO DE PRE PROCESSSAMENTO\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03a5dnwOZ1mA",
        "outputId": "47087d66-5374-46b2-f7dc-2f5ab97b9cf0"
      },
      "source": [
        " pip install git+https://github.com/stanfordnlp/stanza.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/stanfordnlp/stanza.git\n",
            "  Cloning https://github.com/stanfordnlp/stanza.git to /tmp/pip-req-build-stxh15nv\n",
            "  Running command git clone -q https://github.com/stanfordnlp/stanza.git /tmp/pip-req-build-stxh15nv\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza==1.2) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza==1.2) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza==1.2) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza==1.2) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza==1.2) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza==1.2) (54.2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza==1.2) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza==1.2) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza==1.2) (3.7.4.3)\n",
            "Building wheels for collected packages: stanza\n",
            "  Building wheel for stanza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stanza: filename=stanza-1.2-cp37-none-any.whl size=282153 sha256=daea5dc99b1a48fdce2fea6ee4f403af7b797f8a4ad3369f8ff7b486f1b6c318\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7r34njn1/wheels/01/78/62/61318466c5384e887fa693f09fcd651b0d0892bc327c009fcf\n",
            "Successfully built stanza\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYbGyrg9ZwT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b082c3c4-3df2-4ba6-aee1-3898763238a7"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")  # stopwords\n",
        "nltk.download(\"punkt\")  # tokenizador\n",
        "nltk.download('rslp')\n",
        "# nltk.download('wordnet')\n",
        "from nltk import word_tokenize \n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import stanza\n",
        "stanza.download('pt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 55.1MB/s]                    \n",
            "2021-04-14 15:12:12 INFO: Downloading default packages for language: pt (Portuguese)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/pt/default.zip: 100%|██████████| 209M/209M [00:46<00:00, 4.45MB/s]\n",
            "2021-04-14 15:13:05 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsdCoWyPfckd",
        "outputId": "48614e54-ccb4-41ba-c573-936f9f67bc8a"
      },
      "source": [
        "pip install tweet-preprocessor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGIVxElTfjEl"
      },
      "source": [
        "import preprocessor as p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO0eDpNTZQZZ"
      },
      "source": [
        "# STOPWORDS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc7S0hfTzdoY"
      },
      "source": [
        "filtrado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpqMKOPcZjRo"
      },
      "source": [
        "stop = nltk.corpus.stopwords.words(u'portuguese')\n",
        "\n",
        "novo = filtrado\n",
        "\n",
        "\n",
        "test = pd.DataFrame(novo)\n",
        "#test = test[\"Conteudo\"].apply(lambda x: [word for word in x if word not in stop])\n",
        "test['Conteudo'] = test['Conteudo'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yOCsyGzZpS"
      },
      "source": [
        "test = pd.DataFrame(test)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs7mkybcy2nw",
        "outputId": "8e5fe4d4-693e-4a1a-9598-6d6dedea68e2"
      },
      "source": [
        "corpus = test['Conteudo']  # Tweets\n",
        "y = test['Rotulo']  # Rótulos (manual)\n",
        "\n",
        "bow = CountVectorizer()\n",
        "X = bow.fit_transform(corpus)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% Treino -> 20% Teste\n",
        "# print(X_train[:10])\n",
        "# print(y_train[:10])\n",
        "\n",
        "\n",
        "# train = pd.read_csv(\"corpus.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# X_train = bow.transform(train[\"Conteudo\"])\n",
        "# y_train = list(train[\"Rotulo\"])\n",
        "\n",
        "classifier = MLPClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnUI1vve7Sh3"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSSaYfQe7XOn",
        "outputId": "0efb7ca9-0603-4cc7-f231-f34a057913da"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkgV3LYu7e92",
        "outputId": "a47182fe-388d-4340-89da-a28b480270a0"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11424    1\n",
            "8041     1\n",
            "12501    1\n",
            "5663     1\n",
            "6699     1\n",
            "        ..\n",
            "12087    1\n",
            "4078     1\n",
            "5127     1\n",
            "11072    1\n",
            "3793     1\n",
            "Name: Rotulo, Length: 2406, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKNoWzD_7j4e",
        "outputId": "4a0efe98-1916-455a-db5b-14a6d7f55d4a"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.99      0.98      2303\n",
            "           2       0.47      0.27      0.35       103\n",
            "\n",
            "    accuracy                           0.96      2406\n",
            "   macro avg       0.72      0.63      0.66      2406\n",
            "weighted avg       0.95      0.96      0.95      2406\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgtVLW2q7sYu"
      },
      "source": [
        "# stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8jDhV1y722O"
      },
      "source": [
        "stemming = PorterStemmer()\n",
        "\n",
        "est = filtrado \n",
        "    \n",
        "dft = pd.DataFrame(est) \n",
        "\n",
        "dft['Conteudo'] = dft['Conteudo'].apply(lambda x: ' '.join([stemming.stem(word) for word in x.split() ])) # Stem every word.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVbqKwcA-3hL"
      },
      "source": [
        "dft = pd.DataFrame(dft)\n",
        "dft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmZHa3xvNG9e",
        "outputId": "f7f0b180-09b1-463f-8ec2-4720cef57cfb"
      },
      "source": [
        "corpus = dft['Conteudo']  # Tweets\n",
        "y = dft['Rotulo']  # Rótulos (manual)\n",
        "\n",
        "bow = CountVectorizer()\n",
        "X = bow.fit_transform(corpus)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% Treino -> 20% Teste\n",
        "# print(X_train[:10])\n",
        "# print(y_train[:10])\n",
        "\n",
        "\n",
        "# train = pd.read_csv(\"corpus.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# X_train = bow.transform(train[\"Conteudo\"])\n",
        "# y_train = list(train[\"Rotulo\"])\n",
        "\n",
        "classifier = MLPClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oadFiWdVNN21"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_77sPap4NOnW",
        "outputId": "da0ca47f-7462-40a1-b9b3-7225410769ab"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMm3NLX7NQ6W",
        "outputId": "27dead2f-ef1d-41fb-eacd-eadedff9a411"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11424    1\n",
            "8041     1\n",
            "12501    1\n",
            "5663     1\n",
            "6699     1\n",
            "        ..\n",
            "12087    1\n",
            "4078     1\n",
            "5127     1\n",
            "11072    1\n",
            "3793     1\n",
            "Name: Rotulo, Length: 2406, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3eJ47ncNTPn",
        "outputId": "b86532b8-043f-44a4-f18f-4fd3ca144792"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.99      0.98      2303\n",
            "           2       0.48      0.24      0.32       103\n",
            "\n",
            "    accuracy                           0.96      2406\n",
            "   macro avg       0.72      0.62      0.65      2406\n",
            "weighted avg       0.95      0.96      0.95      2406\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy30KrvYPPaG"
      },
      "source": [
        "# Pre-Processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UArG9uVJPSeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f3952a-803f-4656-a3d9-b589866042dc"
      },
      "source": [
        "pro = filtrado \n",
        "pre = pd.DataFrame(pro) \n",
        "\n",
        "pre['Conteudo'] = pre['Conteudo'].apply(lambda x: ' '.join([p.clean(word) for word in x.split() ]))\n",
        "\n",
        "corpus = pre['Conteudo']  # Tweets\n",
        "y = pre['Rotulo']  # Rótulos (manual)\n",
        "\n",
        "bow = CountVectorizer()\n",
        "X = bow.fit_transform(corpus)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% Treino -> 20% Teste\n",
        "# print(X_train[:10])\n",
        "# print(y_train[:10])\n",
        "\n",
        "\n",
        "# train = pd.read_csv(\"corpus.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# X_train = bow.transform(train[\"Conteudo\"])\n",
        "# y_train = list(train[\"Rotulo\"])\n",
        "\n",
        "classifier = MLPClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7dHzD6AP4QA"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTB4RE1x9N22",
        "outputId": "4ad7acb8-77ba-4679-a9cc-f51a0f3eacb3"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzC-PtdG9O2m",
        "outputId": "b53bcc67-bb34-43cb-e1b3-f46935bee6bc"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11424    1\n",
            "8041     1\n",
            "12501    1\n",
            "5663     1\n",
            "6699     1\n",
            "        ..\n",
            "12087    1\n",
            "4078     1\n",
            "5127     1\n",
            "11072    1\n",
            "3793     1\n",
            "Name: Rotulo, Length: 2406, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVa9Tlke9U46",
        "outputId": "a7ec23f8-366d-4b66-a49a-393c8461bab9"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.99      0.98      2303\n",
            "           2       0.42      0.24      0.31       103\n",
            "\n",
            "    accuracy                           0.95      2406\n",
            "   macro avg       0.70      0.61      0.64      2406\n",
            "weighted avg       0.94      0.95      0.95      2406\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbJRsyT8QApf"
      },
      "source": [
        "# Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8D5ZKwXQELt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda174c2-4fb2-445f-d773-28435a0c022b"
      },
      "source": [
        "corpus = filtrado \n",
        "tweets = corpus['Conteudo']  # Tweets\n",
        "y = corpus['Rotulo']\n",
        "\n",
        "# sentence = 'A casa é amarela.'\n",
        "\n",
        "nlp = stanza.Pipeline('pt')\n",
        "\n",
        "\n",
        "#tweets = tweets.apply(lambda x: ' '.join([word.lemma for word in sent.words for sent in doc.sents ]))\n",
        "lemmas = []\n",
        "for i in tweets:\n",
        "  doc = nlp(i)\n",
        "  aux = []\n",
        "  for sent in doc.sentences:\n",
        "    for word in sent.words:\n",
        "      aux.append(word.lemma)\n",
        "  lemmas.append(' '.join(aux))\n",
        "\n",
        "bow = CountVectorizer()\n",
        "X = bow.fit_transform(lemmas)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% Treino -> 20% Teste\n",
        "# print(X_train[:10])\n",
        "# print(y_train[:10])\n",
        "\n",
        "\n",
        "# train = pd.read_csv(\"corpus.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# X_train = bow.transform(train[\"Conteudo\"])\n",
        "# y_train = list(train[\"Rotulo\"])\n",
        "\n",
        "classifier = MLPClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# for i, sent in enumerate()\n",
        "\n",
        "# gg = WordNetLemmatizer()\n",
        "\n",
        "# lemm['Conteudo'] = lemm['Conteudo'].apply(lambda x: ' '.join([gg.lemmatize(word) for word in x.split() ])) # Stem every word.\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-14 15:27:28 INFO: Loading these models for language: pt (Portuguese):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | bosque  |\n",
            "| mwt       | bosque  |\n",
            "| pos       | bosque  |\n",
            "| lemma     | bosque  |\n",
            "| depparse  | bosque  |\n",
            "=======================\n",
            "\n",
            "2021-04-14 15:27:28 INFO: Use device: cpu\n",
            "2021-04-14 15:27:28 INFO: Loading: tokenize\n",
            "2021-04-14 15:27:29 INFO: Loading: mwt\n",
            "2021-04-14 15:27:29 INFO: Loading: pos\n",
            "2021-04-14 15:27:29 INFO: Loading: lemma\n",
            "2021-04-14 15:27:29 INFO: Loading: depparse\n",
            "2021-04-14 15:27:29 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4R_zMzjRI-l"
      },
      "source": [
        "lemmas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkAkYiP29YK6"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvdvJvDP9ZPA",
        "outputId": "11b25372-4275-4b0f-ff3a-890f05c65024"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOHX_85m9Z1Z",
        "outputId": "507a5393-8198-4927-f1ce-b518c5200995"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11424    1\n",
            "8041     1\n",
            "12501    1\n",
            "5663     1\n",
            "6699     1\n",
            "        ..\n",
            "12087    1\n",
            "4078     1\n",
            "5127     1\n",
            "11072    1\n",
            "3793     1\n",
            "Name: Rotulo, Length: 2406, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCUmiAgu9aPO",
        "outputId": "fa9dcbb0-bf93-4afb-f60e-3b34a78fec3b"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.98      0.97      2303\n",
            "           2       0.39      0.25      0.31       103\n",
            "\n",
            "    accuracy                           0.95      2406\n",
            "   macro avg       0.68      0.62      0.64      2406\n",
            "weighted avg       0.94      0.95      0.95      2406\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42pKvK2PF9eF"
      },
      "source": [
        "O DIFERENTE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9eTpDugGAk1",
        "outputId": "ef62e4b3-9ce4-4086-f3fc-35cc5b99b871"
      },
      "source": [
        "stop = nltk.corpus.stopwords.words(u'portuguese')\n",
        "\n",
        "novo = filtrado\n",
        "\n",
        "\n",
        "test = pd.DataFrame(novo)\n",
        "#test = test[\"Conteudo\"].apply(lambda x: [word for word in x if word not in stop])\n",
        "test['Conteudo'] = test['Conteudo'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "test['Conteudo'] = test['Conteudo'].apply(lambda x: ' '.join([p.clean(word) for word in x.split() ]))\n",
        "\n",
        "tweets = test['Conteudo']\n",
        "\n",
        "lemmas = []\n",
        "for i in tweets:\n",
        "  doc = nlp(i)\n",
        "  aux = []\n",
        "  for sent in doc.sentences:\n",
        "    for word in sent.words:\n",
        "      aux.append(word.lemma)\n",
        "  lemmas.append(' '.join(aux))\n",
        "\n",
        "  bow = CountVectorizer()\n",
        "X = bow.fit_transform(lemmas)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # 80% Treino -> 20% Teste\n",
        "# print(X_train[:10])\n",
        "# print(y_train[:10])\n",
        "\n",
        "\n",
        "# train = pd.read_csv(\"corpus.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# X_train = bow.transform(train[\"Conteudo\"])\n",
        "# y_train = list(train[\"Rotulo\"])\n",
        "\n",
        "classifier = MLPClassifier()\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XW2ZyHzG_Jn"
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_vzX68cG_Hz",
        "outputId": "ec8abf88-03df-47a6-c01a-55085865d5b2"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VDmSE_HG_D7",
        "outputId": "b5ddd44d-fd87-42be-84fa-e1746e1ef620"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11424    1\n",
            "8041     1\n",
            "12501    1\n",
            "5663     1\n",
            "6699     1\n",
            "        ..\n",
            "12087    1\n",
            "4078     1\n",
            "5127     1\n",
            "11072    1\n",
            "3793     1\n",
            "Name: Rotulo, Length: 2406, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEICFcnzG-_w",
        "outputId": "43ef6e02-b4c6-4219-bfdc-2dfad772e2d2"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.99      0.98      2303\n",
            "           2       0.44      0.22      0.30       103\n",
            "\n",
            "    accuracy                           0.95      2406\n",
            "   macro avg       0.70      0.61      0.64      2406\n",
            "weighted avg       0.94      0.95      0.95      2406\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}